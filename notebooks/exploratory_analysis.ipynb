{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC 9460 Compliance - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides exploratory analysis of RFC 9460 compliance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.analyzer import calculate_compliance_metrics, analyze_alpn_protocols\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent CSV file\n",
    "results_dir = Path('../results')\n",
    "csv_files = list(results_dir.glob('rfc9460_compliance_*.csv'))\n",
    "\n",
    "if csv_files:\n",
    "    latest_file = max(csv_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Loading: {latest_file}\")\n",
    "    df = pd.read_csv(latest_file)\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "else:\n",
    "    print(\"No CSV files found. Run the checker first.\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"- Total records: {len(df)}\")\n",
    "    print(f\"- Unique domains: {df['domain'].nunique()}\")\n",
    "    print(f\"- Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    print(\"\\nColumn types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC 9460 Adoption Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Calculate adoption rates\n",
    "    metrics = calculate_compliance_metrics(df)\n",
    "    \n",
    "    # Create adoption visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Overall adoption\n",
    "    adoption_data = [\n",
    "        metrics['adoption']['overall_adoption'],\n",
    "        100 - metrics['adoption']['overall_adoption']\n",
    "    ]\n",
    "    axes[0].pie(adoption_data, labels=['Has HTTPS', 'No HTTPS'], \n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "    axes[0].set_title('Overall HTTPS Record Adoption')\n",
    "    \n",
    "    # Root vs WWW comparison\n",
    "    subdomains = ['Root', 'WWW']\n",
    "    adoption_rates = [\n",
    "        metrics['adoption']['root_adoption'],\n",
    "        metrics['adoption']['www_adoption']\n",
    "    ]\n",
    "    axes[1].bar(subdomains, adoption_rates)\n",
    "    axes[1].set_ylabel('Adoption Rate (%)')\n",
    "    axes[1].set_title('HTTPS Adoption by Subdomain')\n",
    "    axes[1].set_ylim(0, 100)\n",
    "    \n",
    "    # Feature distribution\n",
    "    features = list(metrics['features'].keys())\n",
    "    feature_pcts = [metrics['features'][f]['percentage'] for f in features]\n",
    "    axes[2].barh(features, feature_pcts)\n",
    "    axes[2].set_xlabel('Percentage (%)')\n",
    "    axes[2].set_title('RFC 9460 Feature Distribution')\n",
    "    axes[2].set_xlim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP/3 Support Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'has_http3' in df.columns:\n",
    "    # HTTP/3 adoption over subdomains\n",
    "    http3_by_subdomain = df.groupby('subdomain')['has_http3'].mean() * 100\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    http3_by_subdomain.plot(kind='bar')\n",
    "    plt.title('HTTP/3 Support by Subdomain Type')\n",
    "    plt.ylabel('Percentage with HTTP/3 (%)')\n",
    "    plt.xlabel('Subdomain Type')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Domains with HTTP/3\n",
    "    http3_domains = df[df['has_http3'] == True]['domain'].unique()\n",
    "    print(f\"\\nDomains with HTTP/3 support: {len(http3_domains)}\")\n",
    "    if len(http3_domains) <= 20:\n",
    "        print(\"Domains:\")\n",
    "        for domain in sorted(http3_domains)[:20]:\n",
    "            print(f\"  - {domain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALPN Protocol Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'alpn_protocols' in df.columns:\n",
    "    alpn_dist = analyze_alpn_protocols(df)\n",
    "    \n",
    "    if alpn_dist:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        protocols = list(alpn_dist.keys())[:10]  # Top 10\n",
    "        counts = [alpn_dist[p] for p in protocols]\n",
    "        \n",
    "        plt.bar(protocols, counts)\n",
    "        plt.title('Top ALPN Protocols in HTTPS Records')\n",
    "        plt.xlabel('ALPN Protocol')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nALPN Protocol Statistics:\")\n",
    "        for protocol, count in list(alpn_dist.items())[:10]:\n",
    "            print(f\"  {protocol}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECH (Encrypted Client Hello) Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'ech_config' in df.columns:\n",
    "    ech_stats = df.groupby('subdomain')['ech_config'].agg(['sum', 'mean'])\n",
    "    ech_stats['percentage'] = ech_stats['mean'] * 100\n",
    "    \n",
    "    print(\"ECH Configuration Statistics:\")\n",
    "    print(ech_stats)\n",
    "    \n",
    "    # Domains with ECH\n",
    "    ech_domains = df[df['ech_config'] == True]['domain'].unique()\n",
    "    print(f\"\\nDomains with ECH configuration: {len(ech_domains)}\")\n",
    "    if len(ech_domains) > 0 and len(ech_domains) <= 20:\n",
    "        print(\"Domains with ECH:\")\n",
    "        for domain in sorted(ech_domains):\n",
    "            print(f\"  - {domain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP Hints Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # IP hint statistics\n",
    "    ipv4_count = df['ipv4hint'].notna().sum()\n",
    "    ipv6_count = df['ipv6hint'].notna().sum()\n",
    "    both_count = (df['ipv4hint'].notna() & df['ipv6hint'].notna()).sum()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # IP hint distribution\n",
    "    ip_data = ['IPv4 Only', 'IPv6 Only', 'Both', 'Neither']\n",
    "    ip_counts = [\n",
    "        ipv4_count - both_count,\n",
    "        ipv6_count - both_count,\n",
    "        both_count,\n",
    "        len(df) - ipv4_count - ipv6_count + both_count\n",
    "    ]\n",
    "    \n",
    "    ax1.pie(ip_counts, labels=ip_data, autopct='%1.1f%%')\n",
    "    ax1.set_title('IP Hint Distribution')\n",
    "    \n",
    "    # Comparison by subdomain\n",
    "    ip_by_subdomain = df.groupby('subdomain').agg({\n",
    "        'ipv4hint': lambda x: x.notna().mean() * 100,\n",
    "        'ipv6hint': lambda x: x.notna().mean() * 100\n",
    "    })\n",
    "    \n",
    "    ip_by_subdomain.plot(kind='bar', ax=ax2)\n",
    "    ax2.set_title('IP Hints by Subdomain')\n",
    "    ax2.set_ylabel('Percentage (%)')\n",
    "    ax2.set_xlabel('Subdomain')\n",
    "    ax2.legend(['IPv4 Hints', 'IPv6 Hints'])\n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'query_error' in df.columns:\n",
    "    error_counts = df['query_error'].value_counts()\n",
    "    \n",
    "    if not error_counts.empty:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        error_counts.head(10).plot(kind='barh')\n",
    "        plt.title('Top Query Error Types')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Error Type')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nQuery Error Statistics:\")\n",
    "        print(f\"Total queries with errors: {df['query_error'].notna().sum()}\")\n",
    "        print(f\"Error rate: {df['query_error'].notna().mean() * 100:.2f}%\")\n",
    "        print(\"\\nTop error types:\")\n",
    "        for error, count in error_counts.head(5).items():\n",
    "            print(f\"  {error}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compliance Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Calculate compliance scores\n",
    "    def calculate_score(row):\n",
    "        score = 0\n",
    "        if row.get('has_https_record'):\n",
    "            score += 40\n",
    "            if row.get('has_http3'):\n",
    "                score += 20\n",
    "            if row.get('ech_config'):\n",
    "                score += 15\n",
    "            if row.get('ipv4hint') or row.get('ipv6hint'):\n",
    "                score += 15\n",
    "            if row.get('alpn_protocols'):\n",
    "                score += 10\n",
    "        return score\n",
    "    \n",
    "    df['compliance_score'] = df.apply(calculate_score, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['compliance_score'], bins=20, edgecolor='black')\n",
    "    plt.title('Compliance Score Distribution')\n",
    "    plt.xlabel('Compliance Score (0-100)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.axvline(df['compliance_score'].mean(), color='red', \n",
    "                linestyle='--', label=f'Mean: {df[\"compliance_score\"].mean():.1f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    subdomain_scores = df.groupby('subdomain')['compliance_score'].mean()\n",
    "    subdomain_scores.plot(kind='bar')\n",
    "    plt.title('Average Compliance Score by Subdomain')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.xlabel('Subdomain')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCompliance Score Statistics:\")\n",
    "    print(df['compliance_score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Performing Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'compliance_score' in df.columns:\n",
    "    # Calculate average score per domain\n",
    "    domain_scores = df.groupby('domain')['compliance_score'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 20 RFC 9460 Compliant Domains:\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, (domain, score) in enumerate(domain_scores.head(20).items(), 1):\n",
    "        print(f\"{i:2d}. {domain:30s} {score:5.1f}/100\")\n",
    "    \n",
    "    # Visualize top performers\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_10 = domain_scores.head(10)\n",
    "    plt.barh(range(len(top_10)), top_10.values)\n",
    "    plt.yticks(range(len(top_10)), top_10.index)\n",
    "    plt.xlabel('Compliance Score')\n",
    "    plt.title('Top 10 RFC 9460 Compliant Domains')\n",
    "    plt.xlim(0, 100)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Generate summary for export\n",
    "    summary = {\n",
    "        'total_domains': df['domain'].nunique(),\n",
    "        'total_records': len(df),\n",
    "        'adoption_rate': df['has_https_record'].mean() * 100,\n",
    "        'http3_rate': df['has_http3'].mean() * 100,\n",
    "        'ech_rate': df['ech_config'].mean() * 100,\n",
    "        'average_compliance': df.get('compliance_score', pd.Series([0])).mean(),\n",
    "        'scan_date': df['timestamp'].max() if 'timestamp' in df else 'N/A'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nSummary Report:\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in summary.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key:20s}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"{key:20s}: {value}\")\n",
    "    \n",
    "    # Save summary\n",
    "    import json\n",
    "    summary_file = Path('../results/analysis_summary.json')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "    print(f\"\\nSummary saved to: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
